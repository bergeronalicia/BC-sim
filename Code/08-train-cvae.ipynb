{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06bf603-6760-4902-b5be-7e5673b41a0f",
   "metadata": {},
   "source": [
    "# CVAE Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca73d35-c9c1-4f02-8d94-0af9d076cb24",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b0a93b-394b-4d7e-be7c-7ed1100b9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from IPython import display\n",
    "import time\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from make_models import get_MRI_VAE_3D,get_MRI_CVAE_3D\n",
    "from rsa_funcs import fit_rsa,make_RDM,get_triu\n",
    "import ants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802c5c8-d5b7-41f8-a887-917a471d2a72",
   "metadata": {},
   "source": [
    "### Load and Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b453571a-6478-4f35-9708-037dd76a4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = np.load('../../BC-sim/BC-sim-bigdata/synth-data-01/sim-brain-array.npz') # load compressed brain array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d849ebd-07a0-4189-a166-2ed04353d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'controls', 'patients']\n",
      "(1000, 64, 64, 64)\n",
      "(500, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(list(data_arr.keys())) # print data keys\n",
    "data = data_arr['data'] # name data key\n",
    "controls = data_arr['controls'] # name TD/control key\n",
    "patients = data_arr['patients'] # name ADHD/patient key\n",
    "n = data.shape[0] # shape of data\n",
    "print(data.shape) # number of subjects\n",
    "print(data[patients,:,:,:].shape) # print shape of patient data [number of patients, brain voxels x, brain voxels y, brain voxels z]\n",
    "data_patients = data[patients,:,:,:] # name ADHD brain data\n",
    "data_controls = data[controls,:,:,:] # name TD brain data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2e8a2-e02a-4780-9954-ff0a5b728bd3",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d15e8f3-23d6-4fe9-ba0d-98b5d7555e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cvae_data_loader_adhd():\n",
    "    ''' this is the info'''\n",
    "    def __init__(self,data,patients,batch_size=32):\n",
    "    \n",
    "        self.data = data\n",
    "        \n",
    "        self.n = data.shape[0]\n",
    "        self.epoch = -1\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.new_epoch()\n",
    "        self.n_batches = int(np.floor(min((len(self.adhd_idxs),len(self.td_idxs)))/self.batch_size)) # How many batches fit, take the min(n_ADHD,n_TD) then divide by batch size\n",
    "        \n",
    "    def new_epoch(self):\n",
    "\n",
    "        self.adhd_idxs = np.nonzero(patients==True)[0] # idxs of patients\n",
    "        self.td_idxs = np.nonzero(patients==False)[0] # idxs of TDs\n",
    "        \n",
    "        self.adhd_idxs = np.random.permutation(self.adhd_idxs)\n",
    "        self.td_idxs = np.random.permutation(self.td_idxs)\n",
    "        \n",
    "        self.epoch += 1\n",
    "        self.b = 0\n",
    "        \n",
    "        \n",
    "    def get_batch(self):\n",
    "        self.b += 1\n",
    "        \n",
    "        if self.b==self.n_batches:\n",
    "            self.new_epoch()\n",
    "        \n",
    "        self.batch_adhd_idx = self.adhd_idxs[np.arange(self.b*self.batch_size,self.b*self.batch_size+self.batch_size)]\n",
    "        self.batch_td_idx = self.td_idxs[np.arange(self.b*self.batch_size,self.b*self.batch_size+self.batch_size)]\n",
    "        # go through the patients and controls in batch size chunks\n",
    "        # batch_indeces = all_indices[batch number * batch size : batch number * batch size + batch size]\n",
    "        \n",
    "        self.batch_adhd = self.data[self.batch_adhd_idx,:,:,:]\n",
    "        self.batch_td = self.data[self.batch_td_idx,:,:,:]\n",
    "        \n",
    "        _,counts = np.unique(np.hstack((self.batch_adhd_idx,self.batch_td_idx)),return_counts=True)\n",
    "        assert all(counts==1),'not all unique, somethings wrong' # sanity check\n",
    "        \n",
    "        return self.batch_adhd,self.batch_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726bb530-0319-431e-83d6-4a6e22688744",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = cvae_data_loader_adhd(data,patients) # load the dataset through the dataloader to prepare it for cvae training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017970dd-23da-4df2-b1c4-da4d287ba87f",
   "metadata": {},
   "source": [
    "### Tensorflow / GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171f289a-f0fd-43a4-bf7d-49426c8cf869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ # tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6253a3d-8e06-4d12-a80a-5536c1ba5ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name() # GPU check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eaa26d-4375-4df3-9f57-f1aca9e3fd05",
   "metadata": {},
   "source": [
    "### CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80abcf83-3c86-41b5-8641-6730bd5970a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cvae, z_encoder, s_encoder, cvae_decoder = get_MRI_CVAE_3D(input_shape=(64,64,64,1),\n",
    "                    latent_dim=2,\n",
    "                    beta=1, # controls how far away latent features can go from normal distribution, stronger beta = more nromally distributed features\n",
    "                    disentangle=False, # activates the decorrelation from gamma, next time True \n",
    "                    gamma=1, # total correlation loss that penalizes for z and s features being correlated, can be increased to 100\n",
    "                    bias=True,\n",
    "                    batch_size = 64,\n",
    "                    kernel_size = 3,\n",
    "                    filters = 32,\n",
    "                    intermediate_dim = 128,\n",
    "                    opt=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a86e9-4d52-4fd3-ad93-60963588160d",
   "metadata": {},
   "source": [
    "## Train CVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f59c8-9aa0-4766-bb77-b90b7fe0f2aa",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df951678-7b4d-4dee-a28f-6742fe5fea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [22:05:00<00:00, 10.60s/it]   \n"
     ]
    }
   ],
   "source": [
    "# Make sure you have GPU enabled\n",
    "\n",
    "n_epochs = 7500 # 7500 epochs\n",
    "n_batches = data_loader.n_batches # dataloader calculates how many batches\n",
    "loss = [] # start an empty list to add losses to\n",
    "for epoch in tqdm(range(n_epochs)): # for loop runs through every epoch\n",
    "    for batch in range(n_batches): # for loop runs through every batch created by the dataloader\n",
    "        if np.mod(epoch, 10) == 0: # save weights every 10 epochs\n",
    "             cvae.save_weights('/mmfs1/data/bergerar/BC-sim/BC-sim-bigdata/synth-data-01/sim_weights_7500_epochs') # saves weights to that file\n",
    "        adhd_batch, td_batch = data_loader.get_batch() # \n",
    "        l = cvae.train_on_batch([adhd_batch,td_batch]) # [TG,BG]\n",
    "        loss.append(l) # add loss to list\n",
    "        if np.mod(epoch, 10) == 0: # save loss every 10 epochs\n",
    "            np.save('sim_loss_7500_epochs', np.array(loss)) # save loss to that file\n",
    "            \n",
    "# train until variance explained is above 90%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
