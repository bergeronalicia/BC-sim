{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a538940-6eac-4629-a610-cefbd0ed9217",
   "metadata": {},
   "source": [
    "# MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b5dd5-b98e-4be9-be04-63906e8eaea3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e806eee-eff2-45d7-a469-8ff9c000da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from IPython import display\n",
    "import time\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from make_models import get_MRI_VAE_3D,get_MRI_CVAE_3D\n",
    "from rsa_funcs import fit_rsa,make_RDM,get_triu\n",
    "import ants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899d84d-bff3-45d4-85f8-1f7aedf802e5",
   "metadata": {},
   "source": [
    "### Load and Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c20417-77cc-4f54-ab84-da37524e7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = np.load('../../BC-sim/BC-sim-bigdata/synth-data-01/sim-brain-array.npz') # load compressed brain array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d970bcf-ae06-423e-837c-fe7ffc4be5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'controls', 'patients']\n",
      "(1000, 64, 64, 64)\n",
      "(500, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(list(data_arr.keys())) # print data keys\n",
    "data = data_arr['data'] # name data key\n",
    "controls = data_arr['controls'] # name TD/control key\n",
    "patients = data_arr['patients'] # name ADHD/patient key\n",
    "n = data.shape[0] # shape of data\n",
    "print(data.shape) # number of subjects\n",
    "print(data[patients,:,:,:].shape) # print shape of patient data [number of patients, brain voxels x, brain voxels y, brain voxels z]\n",
    "data_patients = data[patients,:,:,:] # name ADHD brain data\n",
    "data_controls = data[controls,:,:,:] # name TD brain data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbf005-c236-4496-9af6-35cda7c4fb5f",
   "metadata": {},
   "source": [
    "### CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c6f8f8-c2c9-41f5-8cfc-1a17896803ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cvae, z_encoder, s_encoder, cvae_decoder = get_MRI_CVAE_3D(input_shape=(64,64,64,1),\n",
    "                    latent_dim=2,\n",
    "                    beta=1, # controls how far away latent features can go from normal distribution, stronger beta = more nromally distributed features\n",
    "                    disentangle=False, # activates the decorrelation from gamma, next time True \n",
    "                    gamma=1, # total correlation loss that penalizes for z and s features being correlated, can be increased to 100\n",
    "                    bias=True,\n",
    "                    batch_size = 64,\n",
    "                    kernel_size = 3,\n",
    "                    filters = 32,\n",
    "                    intermediate_dim = 128,\n",
    "                    opt=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316278d6-c845-49b8-b0ca-b7a2d440f12b",
   "metadata": {},
   "source": [
    "### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bb5c73-c7c7-4d90-9535-0896fb780b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x15544012b340>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae.load_weights('/mmfs1/data/bergerar/BC-sim/BC-sim-bigdata/synth-data-01/sim_weights_7500_epochs') # load weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79833d-bb43-4cb4-abe2-05196d4872d8",
   "metadata": {},
   "source": [
    "### Get Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fcc2a6d-d8a3-46cc-ac07-a75fe31b263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstruction(data_in,adhd = True): \n",
    "    \n",
    "    # reconstructs ADHD brain based on shared and specific features, reconstructs TD based on just shared features\n",
    "\n",
    "    z = z_encoder.predict(data_in)[0] # mu,std,sample\n",
    "    s = s_encoder.predict(data_in)[0]\n",
    "\n",
    "    if adhd==True:\n",
    "        ll = np.hstack((z,s))\n",
    "    else:\n",
    "        ll = np.hstack((z,np.zeros(s.shape)))\n",
    "\n",
    "    recon = cvae_decoder(ll)[:,:,:,:,0]\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258e46e-a6b7-4a07-9890-3b0c0e1ec35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "recon_patients = get_reconstruction(data_patients,adhd = True) # reconstructs ADHD brains\n",
    "recon_controls = get_reconstruction(data_controls,adhd = False) # reconstructs TD brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec3f12-8129-493a-b51a-f48387a90442",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_patients.shape # shape of reconstructed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c689c-fecd-45f1-b39e-f4d9358d773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = data_patients[0,:,:,:]\n",
    "predict_data = recon_patients[0,:,:,:]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mse(true_data, predict_data).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d2fac8-cfec-4e5f-b8ab-dbdd471775eb",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c36690-e28b-4490-b90c-5ee38769c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = [] # start an empty list to add mses to\n",
    "for s in range(0,500): # for loop that runs through all s from 0 to 500\n",
    "    datas = np.array(data_patients[s,:,:,:]) # name original brain\n",
    "    predict = np.array(recon_patients[s,:,:,:]) # name reconstructed brain\n",
    "    mse = ((datas-predict)**2).mean() # \n",
    "    mse_list.append(mse)\n",
    "\n",
    "mse_arr = np.array(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f458c-a9b9-4c2f-9006-16f0149d998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mse_arr, alpha = 0.8, color='chartreuse', edgecolor = 'black', linewidth=0.4 )\n",
    "plt.title('Mean Squared Error for Reconstructions', fontsize = 15)\n",
    "plt.xlabel('MSE', fontsize = 15)\n",
    "plt.ylabel('Number of Subjects', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48888a68-0a66-4743-979f-749ebeb2a26f",
   "metadata": {},
   "source": [
    "### ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89698d-0136-44dd-9989-4ef19cfda7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.reshape(recon_patients, [-1,64,64,64])\n",
    "recon_patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437729a-5afe-4aac-a01f-961f459c079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then subtract mean from original\n",
    "# reshape from 500,64,64,64 to 1,64,64,64 dont just squish all of it down to one dimension\n",
    "\n",
    "mean = ### \n",
    "mean_list = [] # start an empty list to add mses to\n",
    "for s in range(0,500): # for loop that runs through all s from 0 to 500\n",
    "    datas2 = np.array(data_patients[s,:,:,:]) # name original brain\n",
    "    predict2 = np.array(recon_patients[s,:,:,:]) # name reconstructed brain\n",
    "    mean_from_original = ((datas-mean)**2).mean() # \n",
    "    mean_list.append(mean_from_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10d33d-9055-4ed6-bf8a-46fe18eda975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e8e1d-5a8b-48af-b988-f04d097cc7df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
